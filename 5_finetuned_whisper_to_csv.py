from pathlib import Path
import csv

import torch
from transformers import pipeline


def transcribe_to_csv(
    audio_path: Path,
    model_dir: Path,
    output_csv: Path,
    language: str = "chinese", # è¦èˆ‡å¾®èª¿æ™‚ä¸€è‡´
    task: str = "transcribe", # "transcribe"ï¼šè½ä¸­æ–‡ â†’ è¼¸å‡ºä¸­æ–‡, è½å¤–èª â†’ ç¿»æˆè‹±æ–‡
    chunk_length_s: int = 30,
):
    """
    ä½¿ç”¨ã€Œå¾®èª¿å¾Œçš„ Whisperã€å°é•·éŸ³æª”åšè‡ªå‹•åˆ†æ®µï¼Œç›´æ¥è¼¸å‡º csv å­—å¹•ã€‚

    csv æ¬„ä½æ ¼å¼ï¼š
        audio_path, start, end, text

    :param audio_path: è¦è¾¨è­˜çš„éŸ³æª”è·¯å¾‘
    :param model_dir: ä½ å¾®èª¿å¾Œæ¨¡å‹çš„è³‡æ–™å¤¾
    :param output_csv: è¼¸å‡º csv è·¯å¾‘
    :param language: Whisper èªè¨€è¨­å®šï¼ˆè·Ÿè¨“ç·´æ™‚ä¸€æ¨£ï¼Œç”¨ 'chinese'ï¼‰
    :param task: 'transcribe' æˆ– 'translate'
    :param chunk_length_s: pipeline å…§éƒ¨æ¯å¡Šè™•ç†ç§’æ•¸
    """
    if not audio_path.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°éŸ³æª”ï¼š{audio_path}")
    if not model_dir.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ¨¡å‹è³‡æ–™å¤¾ï¼š{model_dir}")

    print("éŸ³æª”ï¼š", audio_path)
    print("ä½¿ç”¨æ¨¡å‹ï¼š", model_dir)

    # 0 = ç¬¬ä¸€å¼µ GPU, -1 = CPU
    device = 0 if torch.cuda.is_available() else -1
    print("ä½¿ç”¨è£ç½®ï¼š", "cuda" if device == 0 else "cpu")

    # å»ºç«‹ ASR pipelineï¼ˆæœƒæ²¿ç”¨ä½ å¾®èª¿å¾Œçš„ tokenizer / feature_extractorï¼‰
    asr = pipeline(
        task="automatic-speech-recognition",
        model=str(model_dir),
        tokenizer=str(model_dir),
        feature_extractor=str(model_dir),
        device=device,
        return_timestamps=True,          # è¦æ±‚å›å‚³æ™‚é–“æˆ³
        chunk_length_s=chunk_length_s,   # é•·éŸ³æª”åˆ†å¡Šè™•ç†
        stride_length_s=(5, 0),          # å‰é¢ä¿ç•™ 5 ç§’åšé‡ç–Šï¼Œé¿å…å¥å­è¢«ç¡¬åˆ‡æ–·
    )

    # Whisper çš„èªè¨€ / ä»»å‹™ç”¨ generate_kwargs å‚³é€²å»
    generate_kwargs = {
        "task": task,
        "language": language,
    }

    print("é–‹å§‹è¾¨è­˜ä¸¦è‡ªå‹•åˆ†æ®µ...")
    result = asr(str(audio_path), generate_kwargs=generate_kwargs)

    # pipeline æœƒå›å‚³ï¼š
    # {
    #   "text": ".....",
    #   "chunks": [
    #       {"text": "...", "timestamp": (start, end)},
    #       ...
    #   ]
    # }
    chunks = result.get("chunks", None)
    if not chunks:
        # ç†è«–ä¸Šä¸å¤ªæœƒç™¼ç”Ÿï¼Œå‚™ç”¨ï¼šæ•´æ®µç•¶ä¸€å¡Š
        print("æ²’æœ‰ chunksï¼Œæ”¹ç”¨æ•´æ®µè¼¸å‡ºä¸€åˆ—ã€‚")
        chunks = [
            {
                "text": result.get("text", "").strip(),
                "timestamp": (0.0, 0.0),  # æ²’æœ‰æ™‚é–“è³‡è¨Š
            }
        ]

    print("ç¸½å…±å–å¾—", len(chunks), "å€‹ç‰‡æ®µã€‚")
    print("è¼¸å‡º CSVï¼š", output_csv)

    with output_csv.open("w", encoding="utf-8-sig", newline="") as f:
        writer = csv.writer(f)
        writer.writerow(["audio_path", "start", "end", "text"])

        for ch in chunks:
            text = (ch.get("text") or "").strip()
            ts = ch.get("timestamp") or (0.0, 0.0)
            start, end = ts

            writer.writerow(
                [
                    str(audio_path),
                    f"{start:.3f}",
                    f"{end:.3f}",
                    text,
                ]
            )

    print("å®Œæˆï¼å·²å¯«å…¥ CSVã€‚")


def main():
    base_dir = Path(__file__).resolve().parent

    # 1. å¾®èª¿å¾Œæ¨¡å‹çš„ä½ç½®
    model_dir = base_dir / "whisper-small-medical-zh"

    # 2. è¦è½‰å­—å¹•çš„é•·éŸ³æª”
    audio_path = (
        base_dir / "Data" / "input" / "ã€æ™ºæ…§å¥åº·èˆ‡é†«ç™‚æŠ€è¡“å•†è«‡åª’åˆæœƒã€‘å¥‡ç¾é†«é™¢ æ™ºæ…§é†«ç™‚ä¸­å¿ƒ æ€¥è¨ºAIç—…æƒ…ç›£æ§å„€è¡¨æ¿.mp3"
    )

    # 3. è¼¸å‡ºçš„ csv è·¯å¾‘
    output_path = (
        base_dir / "Data" / "output" / "ã€æ™ºæ…§å¥åº·èˆ‡é†«ç™‚æŠ€è¡“å•†è«‡åª’åˆæœƒã€‘å¥‡ç¾é†«é™¢ æ™ºæ…§é†«ç™‚ä¸­å¿ƒ æ€¥è¨ºAIç—…æƒ…ç›£æ§å„€è¡¨æ¿.mp3"
    )
    output_csv = output_path.with_suffix(".finetuned.csv")

    # ğŸ”¹ç¢ºä¿ output ç›®éŒ„å­˜åœ¨
    output_csv.parent.mkdir(parents=True, exist_ok=True)

    transcribe_to_csv(
        audio_path=audio_path,
        model_dir=model_dir,
        output_csv=output_csv,
        language="chinese",
        task="transcribe",
        chunk_length_s=30,
    )


if __name__ == "__main__":
    main()
